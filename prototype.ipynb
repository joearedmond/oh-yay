{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4793312-8bcf-41d5-94bb-fdd2f7b2162a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # get API key stored in local file, not committed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07d33337-cc58-4773-9515-43cb58abf31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nOh-yay is a repository that contains a collection of uplifting and positive resources for personal and professional development. This may include inspirational quotes, self-care tips, career advice, and motivational articles. The goal of this repo is to spread joy and encourage personal growth among its users. It may also serve as a platform for individuals to share their own experiences and strategies for finding happiness and success.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n",
    "llm.invoke(\"You are creative. What does a github repo called oh-yay do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d80dbda6-1ba2-45fc-bddb-e784787024bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- LangChain is a framework for developing applications powered by large language models (LLMs).\n",
      "- It simplifies every stage of the LLM application lifecycle, including development, productionization, and deployment.\n",
      "- The framework consists of open-source libraries such as langchain-core, langchain-community, and partner packages for third-party integrations.\n",
      "- The broader ecosystem includes LangSmith for debugging and monitoring, LangGraph for building multi-actor applications, and LangServe for deploying chains as APIs.\n",
      "- The LangChain Expression Language (LCEL) is used to compose chains and is designed for production use.\n",
      "- The framework provides standard and extendable interfaces for components and integrates with other tools.\n",
      "- Security best practices are also provided.\n",
      "- Guides and tutorials are available for use cases such as question answering and chatbots.\n",
      "- The framework is available in Python and JavaScript versions.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader  # wrapper over bs4\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import (\n",
    "    StuffDocumentsChain,\n",
    "    LLMChain,\n",
    ")\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"Write a concise summary of the following content \n",
    "provide the output in bullent points:\n",
    "\n",
    "{content}\n",
    "\n",
    "Summary:\n",
    "\"\"\"  # uses jinja2 formatting\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "map_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=map_chain, document_variable_name=\"content\"\n",
    ")\n",
    "\n",
    "url = \"https://python.langchain.com/docs/get_started/introduction\"\n",
    "loader = WebBaseLoader(url)\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "# this runs without hitting the document limit because the concatenated full document is less than the token limit\n",
    "summary = stuff_chain.run(docs)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "285812d6-fe20-44ff-ba43-b5faa775fcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2637ebc9-d96b-4f13-8b56-f11c4283b747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Transformer is a powerful deep learning architecture for natural language processing, proposed in 2017.\n",
      "- It utilizes self-attention mechanism and has been used in tasks such as machine translation and text summarization.\n",
      "- Transformer has outperformed previous models in benchmarks and has been adapted for other domains.\n",
      "- Different approaches and techniques have been explored to improve its performance.\n",
      "- The article covers topics related to machine learning, such as structured prediction and artificial neural networks.\n",
      "- It discusses the timeline, training, applications, implementations, and architecture of Transformer.\n",
      "- Alternative activation functions, positional encodings, and efficient implementation techniques have been explored.\n",
      "- Different types of attention mechanisms have been used, such as Multi-Query Attention and FlashAttention.\n",
      "- The article also covers the use of Transformer in other domains, such as speech recognition and image recognition.\n",
      "- It discusses the use of differentiable computing and its applications, including image and speech recognition, NLP, and robotics.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\" # larger document\n",
    "loader = WebBaseLoader(url)\n",
    "data = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "map_template = \"\"\"Write a concise summary of the following content:\n",
    "\n",
    "{content}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(prompt=map_prompt, llm=llm)\n",
    "\n",
    "reduce_template = \"\"\"The following is set of summaries:\n",
    "\n",
    "{doc_summaries}\n",
    "\n",
    "Summarize the above summaries with all the key details\n",
    "Summary:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "reduce_chain = LLMChain(prompt=reduce_prompt, llm=llm)\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    ")\n",
    "\n",
    "reduce_chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=stuff_chain,\n",
    ")\n",
    "summary = map_reduce_chain.run(docs)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a0deace-fd51-4240-8003-1e00c617590a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2a6a8-b342-414d-8f32-4c7f206ff9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
